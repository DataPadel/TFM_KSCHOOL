{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IMAGES RECOGNITION/CLASSIFICATION WITH MACHINE LEARNING ALGORITHMS:\n",
        "\n",
        "<img src= \"https://codeit.us/storage/oljJjUu9wQjm5YWnqnlkqAKo1KwBlhlY3DCl7Fdv.jpeg\" height = '400'>\n"
      ],
      "metadata": {
        "id": "1IglvmqorjCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[TOP 5 ALGORITHMS](https://medium.com/@mansi89mahi/5-best-machine-learning-algorithms-4-image-recognition-ab0eee5e2931)"
      ],
      "metadata": {
        "id": "gxm9ExFHroum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<mark>Debemos tener en cuenta que el reconocimiento de imágenes es una parte del aprendizaje profundo, por lo que debemos entender la diferencia entre esto y el aprendizaje automático:\n",
        "\n",
        "*El aprendizaje automático y el aprendizaje profundo son ambos tipos de IA. En resumen, el aprendizaje automático es una IA que puede adaptarse automáticamente con mínima interferencia humana. El aprendizaje profundo es un subconjunto del aprendizaje automático que utiliza redes neuronales artificiales para imitar el proceso de aprendizaje del cerebro humano.*"
      ],
      "metadata": {
        "id": "Ol8K7QC_sl5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[INTERESTING VIDEO ABOUT IMAGE PROCESSING](https://www.youtube.com/watch?v=kSqxn6zGE0c)"
      ],
      "metadata": {
        "id": "R9EA0m2JsriF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bk28YiaG0jWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación de un Algoritmo de IA para el clasificación de Imágenes para Recomendar Raquetas de Pádel Basado en el Estilo de Juego y Prevención de Lesiones, pasos que debemos de seguir\n",
        "\n",
        "\n",
        "\n",
        "### 1. **Recopilación de Datos:**\n",
        "   - **Imágenes:** Recopilar un gran conjunto de imágenes que muestren diferentes estilos de juego y golpes.\n",
        "\n",
        "     -- *Imágenes de Golpes de Pádel:* Captura imágenes que muestren varios tipos de golpes en pádel (por ejemplo, smashes, lobs, drives).\n",
        "\n",
        "     --*Estilos de Juego:* Asegúrate de que las imágenes reflejen diferentes estilos de juego (por ejemplo, agresivo, defensivo).\n",
        "\n",
        "     --*Datos de Lesiones:* Si es posible, reúne información sobre qué estilos están asociados con lesiones específicas.\n",
        "\n",
        "   - **Anotaciones:** Etiquetar las imágenes con el tipo de golpe y cualquier detalle relevante sobre el estilo . *ESTO DEBE SER Anotado manualmente: imágenes con etiquetas para el tipo de golpe (por ejemplo, smash, lob) y estilo (por ejemplo, agresivo, defensivo).\n",
        "\n",
        "**LABELING TOOLS** (PARA CLASIFICAR LAS IMÁGENES POR NOMBRE):\n",
        "  \n",
        ". LabelImg: Una herramienta gratuita para etiquetar imágenes con diferentes categorías, adecuada para crear datasets de detección de objetos.\n",
        "\n",
        ". VIA (VGG Image Annotator): Una herramienta en línea para la anotación de imágenes, útil para etiquetar diferentes características y clases.\n",
        "\n",
        ". RectLabel (para macOS): Una aplicación completa para anotar y gestionar datasets de imágenes.\n",
        "   \n",
        "\n",
        "### 2. **Preprocesamiento:**\n",
        "   - **Preprocesamiento de Imágenes:** Redimensionar, normalizar y aumentar imágenes para mejorar la generalización del modelo.\n",
        "   - **División de Datos:** Dividir el conjunto de datos en conjuntos de entrenamiento, validación y prueba.\n",
        "\n",
        "### 3. **Selección del Modelo:**\n",
        "   - Usar Redes Neuronales Convolucionales (CNN) para la clasificación de imágenes.  Este link explica bastante bien como funcionan aunque es algo técnico\n",
        "   https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks\n",
        "\n",
        "   - Considerar el aprendizaje transferido con modelos preentrenados como VGG16, ResNet50 o InceptionV3.\n",
        "\n",
        "### 4. **Entrenamiento del Modelo:**\n",
        "   - Definir la arquitectura del modelo.\n",
        "   - Entrenar el modelo utilizando el conjunto de datos de entrenamiento.\n",
        "   - Validar el modelo en el conjunto de datos de validación.\n",
        "\n",
        "### 5. **Evaluación:**\n",
        "   - Evaluar el rendimiento del modelo en el conjunto de datos de prueba.\n",
        "   - Ajustar el modelo basado en las métricas de rendimiento (precisión, precisión, recall).\n",
        "\n",
        "### 6. **Sistema de Recomendación:**\n",
        "   - Desarrollar un sistema de recomendación que asocie los estilos de juego con raquetas específicas.\n",
        "   - Incluir datos de prevención de lesiones para recomendar raquetas que ayuden a evitar lesiones.\n",
        "\n",
        "### 7. **Integración:**\n",
        "   - Integrar el modelo en una aplicación web o móvil donde los usuarios puedan subir imágenes y recibir recomendaciones.\n",
        "\n",
        "### Ahora dejo los pasos con código que he conseguido de diferentes páginas y chat gpt:\n",
        "\n",
        "#### **Paso 1: Recopilación de Datos**\n",
        "Necesitamos asegurarnos de tener un conjunto de datos diverso y bien etiquetado.\n",
        "\n",
        "#### **Paso 2: Preprocesamiento**\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            label = filename.split('_')[0]  # Asumiendo que la etiqueta es parte del nombre del archivo\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "images, labels = load_images_from_folder('ruta/a/dataset')\n",
        "\n",
        "# Redimensionar imágenes\n",
        "images = [cv2.resize(img, (224, 224)) for img in images]\n",
        "\n",
        "# Normalizar imágenes\n",
        "images = np.array(images) / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Dividir el conjunto de datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "#### **Paso 3: Selección y Entrenamiento del Modelo**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Usando aprendizaje transferido con VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Congelar el modelo base\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')  # num_classes debería ser el número de estilos de juego\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Aumento de datos\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=20)\n",
        "```\n",
        "\n",
        "#### **Paso 4: Evaluación**\n",
        "\n",
        "```python\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Precisión en prueba: {accuracy:.2f}')\n",
        "```\n",
        "\n",
        "#### **Paso 5: Sistema de Recomendación**\n",
        "\n",
        "```python\n",
        "# Función dummy para recomendación basada en el estilo de juego\n",
        "def recommend_racket(style):\n",
        "    recommendations = {\n",
        "        'agresivo': 'Raqueta A',\n",
        "        'defensivo': 'Raqueta B',\n",
        "        'balanceado': 'Raqueta C'\n",
        "    }\n",
        "    injury_prevention = {\n",
        "        'agresivo': 'Raqueta X',\n",
        "        'defensivo': 'Raqueta Y',\n",
        "        'balanceado': 'Raqueta Z'\n",
        "    }\n",
        "    return recommendations.get(style, 'Raqueta Predeterminada'), injury_prevention.get(style, 'Raqueta de Prevención de Lesiones Predeterminada')\n",
        "\n",
        "# Ejemplo de uso\n",
        "style = 'agresivo'\n",
        "racket, injury_prevention_racket = recommend_racket(style)\n",
        "print(f'Recomendada: {racket}, Raqueta de Prevención de Lesiones: {injury_prevention_racket}')\n",
        "```\n",
        "\n",
        "#### **Paso 6: Integración**\n",
        "\n",
        "Integrar el modelo en tu aplicación web o móvil. Esto es un ejemplo de código de CHAT GPT de Flask para el back-end:\n",
        "\n",
        "```python\n",
        "from flask import Flask, request, jsonify\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = load_model('ruta/a/tu/modelo.h5')\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image / 255.0\n",
        "    return np.expand_dims(image, axis=0)\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    file = request.files['file']\n",
        "    image = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "    processed_image = preprocess_image(image)\n",
        "    prediction = model.predict(processed_image)\n",
        "    predicted_style = np.argmax(prediction, axis=1)[0]\n",
        "    \n",
        "    racket, injury_prevention_racket = recommend_racket(predicted_style)\n",
        "    return jsonify({'recommended_racket': racket, 'injury_prevention_racket': injury_prevention_racket})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "```"
      ],
      "metadata": {
        "id": "8PFZJI7Pstxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AHORA EMPEZAMOS A PERSONALIZARLO CON DATOS DEL PROYECTO\n",
        "\n",
        "1. RECOLECCIÓN DE IMÁGENES\n",
        "\n",
        "- Según tipo de golpe:\n",
        "  1. Smash\n",
        "  2. Drive\n",
        "  3. Revés\n",
        "  4. Salida pared\n",
        "  5. Víbora"
      ],
      "metadata": {
        "id": "Cp2lQM9_2HMs"
      }
    }
  ]
}